#!/usr/bin/env bash

# Welcome to the setup script for S3 backup and Processing

fancy_echo() {
  printf "\n%b\n" "$1"
}

set -e

BACKUP_PATH_DEFAULT="$HOME/backups"
read -p "Please provide a path you would like to save backups [$BACKUP_PATH_DEFAULT]:" BACKUP_PATH
BACKUP_PATH=${BACKUP_PATH:-$BACKUP_PATH_DEFAULT}

SITE_BACKUP_SRC_DEFAULT="/var/www"
read -p "Please provide a path you would like to backup from [$SITE_BACKUP_SRC_DEFAULT]:" SITE_BACKUP_SRC
SITE_BACKUP_SRC=${SITE_BACKUP_SRC:-$SITE_BACKUP_SRC_DEFAULT}

read -p "Would you like to backup a MYSQL database? (y/n) [n]:" MYSQL_BACKUP
MYSQL_BACKUP=${MYSQL_BACKUP}
if [[ $MYSQL_BACKUP -eq "y"] || [$MYSQL_BACKUP -eq "Y"]]; then
  read -p "Please provide the MYSQL user you would like to save the database for:" MYSQL_USER
  MYSQL_USER=${MYSQL_USER}

  read -p "Please provide the MYSQL password:" MYSQL_PASSWORD
  MYSQL_PASSWORD=${MYSQL_PASSWORD}

  MYSQL_SERVER_DEFAULT="localhost"
  read -p "Please provide the server you would like to backup from [$MYSQL_SERVER_DEFAULT]:" MYSQL_SERVER
  MYSQL_SERVER=${MYSQL_SERVER:-$MYSQL_SERVER_DEFAULT}
fi
read -p "Please provide the AWS bucket name you would like to back up to:" AWS_BUCKETNAME
AWS_BUCKETNAME=${AWS_BUCKETNAME}

fancy_echo "Creating folder at $BACKUP_PATH"

if [[ ! -d "$BACKUP_PATH" ]]; then
  mkdir "$BACKUP_PATH"
  fancy_echo "Created $BACKUP_PATH"
else
  fancy_echo "Folder already exists, using that instead."
fi

if [[ ! -d "$BACKUP_PATH/sites" ]]; then
  mkdir "$BACKUP_PATH/sites"
fi

if [[ ! -d "$BACKUP_PATH/databases" ]]; then
  mkdir "$BACKUP_PATH/databases"
fi


fancy_echo "Now downloading Amazon S3 and Configuring..."

if [[ ! -d "$BACKUP_PATH/tmp" ]]; then
  mkdir "$BACKUP_PATH/tmp"
else
  fancy_echo "Folder already exists, using that instead."
fi
wget https://s3.amazonaws.com/aws-cli/awscli-bundle.zip -P "$BACKUP_PATH/tmp/"

unzip "$BACKUP_PATH/tmp/awscli-bundle.zip" -d "$BACKUP_PATH/tmp/"

$BACKUP_PATH/tmp/awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
/usr/local/bin/aws configure

fancy_echo "Finished installing and setting up AWS"
fancy_echo "Setting rest of the scripts up"

if [[ $MYSQL_BACKUP -eq "y"] || [$MYSQL_BACKUP -eq "Y"]]; then
  /bin/cat <<EOM >$BACKUP_PATH/mysql
  mysql -s -r -u $MYSQL_USER -p$MYSQL_PASSWORD -e 'show databases' | while read db; do mysqldump --skip-lock-tables -u $MYSQL_SERVER -p$MYSQL_PASSWORD $db -r $BACKUP_PATH/databases/raw/${db}.sql; [[ $? -eq 0 ]] && gzip ~/backup/databases/raw/${db}.sql; done
EOM

  chmod 775 "$BACKUP_PATH/mysql"
fi

/bin/cat <<EOM >$BACKUP_PATH/run
#!/bin/sh

# grab all sites and create a tar.gz archive
/bin/tar -cvpzf $BACKUP_PATH/sites/site_`date +%d-%m-%Y`.tar.gz $SITE_BACKUP_SRC

# create a folder where we can dump all the raw .sql files
mkdir -p $BACKUP_PATH/databases/raw/ # this is a temp directory, it'll be deleted later

if [[ $MYSQL_BACKUP -eq "y"] || [$MYSQL_BACKUP -eq "Y"]]; then
  # grab all mysql databases
  $BACKUP_PATH/mysql # a python script

  # grab all raw .sql files and create a tar.gz archive
  /bin/tar -cvpzf $BACKUP_PATH/databases/db_$(date '+%d-%m-%Y').tar.gz ~/backup/databases/raw/


# delete the /raw/ directory once archived
rm -rf $BACKUP_PATH/databases/raw/
fi

# push the files to S3
/usr/local/bin/aws s3 cp --recursive $BACKUP_PATH/sites s3://$AWS_BUCKETNAME
/usr/local/bin/aws s3 cp --recursive $BACKUP_PATH/databases s3://$AWS_BUCKETNAME

# delete the contents of the other directories as we don't need to store them once backed up
rm -rf $BACKUP_PATH/sites/*
if [[ $MYSQL_BACKUP -eq "y"]] || [[$MYSQL_BACKUP -eq "Y"]]; then
  rm -rf $BACKUP_PATH/databases/*
fi

EOM

chmod 775 "$BACKUP_PATH/run"

fancy_echo "Adding default schedule to CRON"
crontab -l > "$BACKUP_PATH/tmp/mycron"
echo "0 1 * * * $BACKUP_PATH/run" >> "$BACKUP_PATH/tmp/mycron"
crontab "$BACKUP_PATH/tmp/mycron"
rm "$BACKUP_PATH/tmp/mycron"

fancy_echo "If you would like to alter the script please alter the CRON Job \"crontab -e\""

rm -rf "$BACKUP_PATH/tmp"

fancy_echo "All done! Welcome to the world of S3 Backups."
